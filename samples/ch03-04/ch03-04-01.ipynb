{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 TF-IDF のサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 3.4.1 Wikipediaの日本百名湯記事をTF-IDFで分析\n",
    "\n",
    "# 日本百名湯のうち、wikipediaに記事のある温泉のリスト\n",
    "\n",
    "spa_list = ['菅野温泉','養老牛温泉','定山渓温泉','登別温泉','洞爺湖温泉','ニセコ温泉郷','朝日温泉 (北海道)',\n",
    "          '酸ヶ湯温泉','蔦温泉', '花巻南温泉峡','夏油温泉','須川高原温泉','鳴子温泉郷','遠刈田温泉','峩々温泉',\n",
    "           '乳頭温泉郷','後生掛温泉','玉川温泉 (秋田県)','秋ノ宮温泉郷','銀山温泉','瀬見温泉','赤倉温泉 (山形県)',\n",
    "           '東山温泉','飯坂温泉','二岐温泉','那須温泉郷','塩原温泉郷','鬼怒川温泉','奥鬼怒温泉郷',\n",
    "           '草津温泉','伊香保温泉','四万温泉','法師温泉','箱根温泉','湯河原温泉',\n",
    "           '越後湯沢温泉','松之山温泉','大牧温泉','山中温泉','山代温泉','粟津温泉',\n",
    "           '奈良田温泉','西山温泉 (山梨県)','野沢温泉','湯田中温泉','別所温泉','中房温泉','白骨温泉','小谷温泉',\n",
    "           '下呂温泉','福地温泉','熱海温泉','伊東温泉','修善寺温泉','湯谷温泉 (愛知県)','榊原温泉','木津温泉',\n",
    "           '有馬温泉','城崎温泉','湯村温泉 (兵庫県)','十津川温泉','南紀白浜温泉','南紀勝浦温泉','湯の峰温泉','龍神温泉',\n",
    "           '奥津温泉','湯原温泉','三朝温泉','岩井温泉','関金温泉','玉造温泉','有福温泉','温泉津温泉',\n",
    "           '湯田温泉','長門湯本温泉','祖谷温泉','道後温泉','二日市温泉 (筑紫野市)','嬉野温泉','武雄温泉',\n",
    "           '雲仙温泉','小浜温泉','黒川温泉','地獄温泉','垂玉温泉','杖立温泉','日奈久温泉',\n",
    "           '鉄輪温泉','明礬温泉','由布院温泉','川底温泉','長湯温泉','京町温泉',\n",
    "           '指宿温泉','霧島温泉郷','新川渓谷温泉郷','栗野岳温泉']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipediaの記事の読み取り\n",
    "# 2.1節参照\n",
    "import wikipedia\n",
    "wikipedia.set_lang(\"ja\")\n",
    "\n",
    "content_list = []\n",
    "for spa in spa_list:\n",
    "    print(spa)\n",
    "    content = wikipedia.page(spa,auto_suggest=False).content\n",
    "    content_list.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素解析\n",
    "# 2.2節参照\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenneizerインスタンスの生成\n",
    "t = Tokenizer()\n",
    "\n",
    "# 形態素解析関数の定義\n",
    "def tokenize(text):\n",
    "    return [token.base_form for token in t.tokenize(text) \n",
    "    if token.part_of_speech.split(',')[0] in['名詞','形容詞']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia記事を名詞と形容詞のみとし、ブランクで分かち書き\n",
    "# 2.2節参照\n",
    "\n",
    "words_list = []\n",
    "for content in content_list:\n",
    "    words = ' '.join(tokenize(content))\n",
    "    words = words.replace('==', '')\n",
    "    words_list.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 3.4.2\n",
    "# TF-IDF分析の実施\n",
    "\n",
    "# ライブラリのインポート\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizerの初期化\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_df=50)\n",
    "\n",
    "# フィーチャーベクトルの生成\n",
    "features = vectorizer.fit_transform(words_list)\n",
    "\n",
    "# 特徴語の抽出\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# フィーチャーベクトルをTF-IDF行列に変換 (numpy の ndarray 形式)\n",
    "tfidfs = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト3.4.3 温泉毎の特徴語の表示\n",
    "\n",
    "# TF-IDFの結果からi番目のドキュメントの特徴的な上位n語を取り出す関数\n",
    "def extract_feature_words(terms, tfidfs, i, n):\n",
    "    \n",
    "    # i番目の項目のtfidfsの値リストを作成\n",
    "    tfidf_array = tfidfs[i]\n",
    "    \n",
    "    # tfidf_arrayの値が小さい順にソートした時のインデックスリストを作る\n",
    "    sorted_idx = tfidf_array.argsort()\n",
    "    \n",
    "    # インデックスリストを逆順に (値が大きい順のインデックスとなる)\n",
    "    sorted_idx_rev = sorted_idx[::-1]\n",
    "    \n",
    "    # トップnのみを抽出\n",
    "    top_n_idx = sorted_idx_rev[:n]  \n",
    "        \n",
    "    # インデックスに該当する単語リスト作成\n",
    "    words = [terms[idx] for idx in top_n_idx]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# 結果の出力\n",
    "for i in range(10):\n",
    "    print(  '【' + spa_list[i] + '】' )\n",
    "    for x in  extract_feature_words(terms, tfidfs, i, 10):\n",
    "        print(x, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
